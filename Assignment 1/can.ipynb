{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06428d02-fcec-4e5c-9930-b1b365c68a10",
   "metadata": {},
   "source": [
    "# Context Aggregation Networks (CAN)\n",
    "### Introduction\n",
    "This code details the implementation of a Convolutional Attention Network (CAN) using PyTorch for classifying the MNIST dataset. The MNIST dataset consists of 28x28 grayscale images of handwritten digits (0-9). The goal is to classify these images into one of the 10 digit classes.\\\n",
    "\\\n",
    "Note:\n",
    "- CNN model with dilated convolutions\n",
    "- Similar model: Dilated Residual Networks (CVPR 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42adb8-6744-4f22-a950-fbb158b061cc",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "We define the following hyperparameters:\n",
    "- `batch_size`: Number of samples per batch.\n",
    "- `num_classes`: Number of output classes (10 for digits 0-9).\n",
    "- `learning_rate`: Learning rate for the optimizer.\n",
    "- `num_epochs`: Number of times the entire dataset is passed through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c144d4-b823-40db-8831-8a4f7414e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in relevant libraries, and alias where appropriate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82040dc-35fd-4e5e-9409-265fdc20e7a8",
   "metadata": {},
   "source": [
    "### Data Loading and Transformation\n",
    "We load the MNIST dataset and apply transformations to resize the images to 32x32 (as required by the model), convert them to tensors, and normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02504712-eb5b-4a6d-a064-4c02acd4bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset and preprocessing\n",
    "train_dataset = datasets.MNIST(root = './MNIST',\n",
    "                               train = True,\n",
    "                               transform = transforms.Compose([\n",
    "                               transforms.Resize((32,32)),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                               download = True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root = './MNIST',\n",
    "                              train = False,\n",
    "                              transform = transforms.Compose([\n",
    "                              transforms.Resize((32,32)),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                              download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7166eec6-d1c2-47c3-a174-c82f2faddede",
   "metadata": {},
   "source": [
    "### CAN Model\n",
    "We define the CANModel, which consists of five convolutional layers with increasing dilation rates and padding to maintain the spatial dimensions. The activation function used is LeakyReLU, and an adaptive average pooling layer is used before the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54628c39-e0a9-4237-a127-d5d5a9d9ac32",
   "metadata": {},
   "source": [
    "![CAN](https://i.imgur.com/Yy6NOS1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de231495-b9d8-4d68-9b7c-99a893475f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CANModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CANModel, self).__init__()\n",
    "        # Define the layers of the CAN model with padding\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, dilation=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, dilation=2, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, dilation=4, padding=4)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, dilation=8, padding=8)\n",
    "        self.conv5 = nn.Conv2d(32, 10, kernel_size=3, dilation=1, padding=1)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply layers with LeakyReLU activation function\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = F.leaky_relu(self.conv5(x))\n",
    "        \n",
    "        # Global Average Pooling layer before final output\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10e980-8a8e-4960-9a6b-86f732fd0188",
   "metadata": {},
   "source": [
    "### Model, Loss Function, and Optimizer\n",
    "We instantiate the model, define the loss function as `CrossEntropyLoss`, and use the `Adam` optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1952a8df-8df4-41b0-8594-d5ef0b735e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CANModel().to(device)\n",
    "\n",
    "#Setting the loss function\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "#Setting the optimizer with the model parameters and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#this is defined to print how many steps are remaining when training\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e6270-1f15-4349-968c-b74d93940fef",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "We train the model for the specified number of epochs. During each epoch:\n",
    "- Forward pass: Compute the model’s predictions.\n",
    "- Compute the loss.\n",
    "- Backward pass: Compute gradients.\n",
    "- Update the model parameters using the optimizer.\n",
    "- Track the running loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b38d0f2b-bdcf-4693-996b-0c58914275c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.3412, Accuracy: 88.22%\n",
      "Epoch [2/20], Loss: 0.0560, Accuracy: 98.22%\n",
      "Epoch [3/20], Loss: 0.0437, Accuracy: 98.67%\n",
      "Epoch [4/20], Loss: 0.0393, Accuracy: 98.80%\n",
      "Epoch [5/20], Loss: 0.0335, Accuracy: 99.00%\n",
      "Epoch [6/20], Loss: 0.0345, Accuracy: 98.92%\n",
      "Epoch [7/20], Loss: 0.0300, Accuracy: 99.09%\n",
      "Epoch [8/20], Loss: 0.0301, Accuracy: 99.07%\n",
      "Epoch [9/20], Loss: 0.0259, Accuracy: 99.22%\n",
      "Epoch [10/20], Loss: 0.0274, Accuracy: 99.24%\n",
      "Epoch [11/20], Loss: 0.0273, Accuracy: 99.20%\n",
      "Epoch [12/20], Loss: 0.0262, Accuracy: 99.26%\n",
      "Epoch [13/20], Loss: 0.0219, Accuracy: 99.35%\n",
      "Epoch [14/20], Loss: 0.0269, Accuracy: 99.24%\n",
      "Epoch [15/20], Loss: 0.0229, Accuracy: 99.33%\n",
      "Epoch [16/20], Loss: 0.0203, Accuracy: 99.38%\n",
      "Epoch [17/20], Loss: 0.0223, Accuracy: 99.38%\n",
      "Epoch [18/20], Loss: 0.0240, Accuracy: 99.32%\n",
      "Epoch [19/20], Loss: 0.0252, Accuracy: 99.30%\n",
      "Epoch [20/20], Loss: 0.0165, Accuracy: 99.52%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = cost(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Track accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    avg_loss = running_loss / total_step\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "          .format(epoch+1, num_epochs, avg_loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f16395-c8ee-41dd-80cb-4573462e9d50",
   "metadata": {},
   "source": [
    "### Testing the Model\n",
    "We evaluate the model on the test dataset without computing gradients to save memory. We calculate the accuracy of the model on the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3632df82-3bab-4511-b73e-2932bd67533f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 99.1 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "  \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659cfc0-c329-480f-a5c9-378ae597f47b",
   "metadata": {},
   "source": [
    "### Results\n",
    "With a CAN model, an accuracy of 99.1% is achieved on the MNIST test dataset.\\\n",
    "\\\n",
    "With different number of feature channels (Note: due to long runtime, it's run seperately, only the accuracy results are present):\n",
    "- 16 channels accuracy: 99.15%\n",
    "- 32 channels accuracy: 99.1%\n",
    "- 64 channels accuracy: 97.38%\n",
    "\n",
    "As Comparisons:\n",
    "- KNN model (k=3) accuracy: 96.33%\n",
    "- MLP model (n=128) accuracy: 96.75%\n",
    "- LeNet-5 model (modified) accuracy: 98.85%\n",
    "\n",
    "### Discussion (CAN with diff. num. of channels)\n",
    "For channels (c in short) is 16 and 32, CAN model achieved accuracy of 99.15% and 99.1%. However when c=64, the accuracy was unexpected lower (97.38%), as learning rate (lr) of 0.01 is used across 3 models.\n",
    "- For c=16 & c=32, lr=0.01 was effective likely because the model’s capacity was balanced with the learning rate, allowing for stable and efficient training.\n",
    "- For c=64, as capacity increases, lr=0.01 might be too aggressive, causing the model to overshoot the optimal weights during training. This can result in lower accuracy compared to configurations with fewer feature channels.\n",
    "\n",
    "Potential Solutions:\n",
    "- Learning Rate Adjustment: For c=64, reduce lr from 0.01 to 0.001, might allow the model to converge more smoothly and avoid overshooting.\n",
    "- Learning Rate Scheduling: Implementing a learning rate scheduler that decreases the learning rate over time can help the model fine-tune its weights more effectively as training progresses.\n",
    "\n",
    "### Discussion (CAN with Other Models)\n",
    "Several factors contribute to the superior performance of the CAN:\n",
    "1. **Activation Function (Leaky ReLU vs ReLU)**:\n",
    "- CAN uses LeakyReLU, which address the “dying ReLU” problem by allowing a small, non-zero gradient when the unit is not active. (helps maintain gradient flow and improves learning stability)\n",
    "- Modified LeNet-5 uses ReLU, which can sometimes lead to neurons becoming inactive and not contributing to learning.\n",
    "\n",
    "2. **Dilated Convolutions**:\n",
    "- It allow the network to have a larger receptive field without increasing the number of parameters.\n",
    "- This helps in capturing more contextual information from the input images, leading to better feature extraction and improved classification performance.\n",
    "\n",
    "3. **Global Average Pooling**:\n",
    "-  It helps reduce the number of parameters and prevents overfitting.\n",
    "-  It also ensures that the spatial dimensions are reduced effectively, leading to a more compact and efficient representation of the features.\\\n",
    "\n",
    "### Issue to address\n",
    "However, one notable issue with LeakyReLU is that it can take longer to train compared to ReLU. The reason might be LeakyReLU introduces a small gradient for negative inputs, which can slow down the convergence rate.\n",
    "\n",
    "### Conclusion\n",
    "- The CANModel demonstrates superior performance in classifying MNIST images, achieving an accuracy of 99.1%. \n",
    "- This is attributed to the use of LeakyReLU activation functions, dilated convolutions, and global average pooling, which collectively enhance the model’s ability to learn and generalize from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98c168-4900-43ba-852b-a5725091eddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
